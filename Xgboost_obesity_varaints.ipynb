{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0uC3tw6cjL4AWvxf5r1+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuvrajDesh/Xgboost_obesity/blob/main/Xgboost_obesity_varaints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Subject:** Machine Learning\n",
        "**Team Name:** MT2025135_MT2025040  \n",
        "**Member 1:** Yuvraj Deshmukh **Roll No:** MT2025040  \n",
        "**Member 2:** Yash Parande  **Roll No:** MT2025135\n"
      ],
      "metadata": {
        "id": "pJbOyrQdg6mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  run 16 XGBoost variants\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import json\n",
        "\n",
        "SEED = 42\n",
        "VALID_SIZE = 0.20\n",
        "\n",
        "OUT_PREFIX = \"submission_model_\"   # will append number + .csv\n",
        "LOG_CSV = \"model_results.csv\"\n",
        "\n",
        "#  Load data\n",
        "if not os.path.exists(\"train.csv\") or not os.path.exists(\"test.csv\"):\n",
        "    raise FileNotFoundError(\"Please put train.csv and test.csv in the working directory before running this script.\")\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "#  Preserve test ids\n",
        "if \"id\" in test_df.columns:\n",
        "    test_ids = test_df[\"id\"].copy()\n",
        "else:\n",
        "    test_ids = pd.Series(np.arange(len(test_df)), name=\"id\")\n",
        "\n",
        "# Drop id from train if present\n",
        "if \"id\" in train_df.columns:\n",
        "    train_df = train_df.drop(columns=[\"id\"])\n",
        "\n",
        "#  Separate target\n",
        "TARGET = \"WeightCategory\"\n",
        "if TARGET not in train_df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET}' not found in train.csv\")\n",
        "y_raw = train_df[TARGET].astype(str).copy()\n",
        "X_train_raw = train_df.drop(columns=[TARGET]).reset_index(drop=True)\n",
        "X_test_raw = test_df.copy()\n",
        "if \"id\" in X_test_raw.columns:\n",
        "    X_test_raw = X_test_raw.drop(columns=[\"id\"])\n",
        "X_test_raw = X_test_raw.reset_index(drop=True)\n",
        "\n",
        "#  Basic cleaning\n",
        "for df in (X_train_raw, X_test_raw):\n",
        "    for c in df.columns:\n",
        "        # numeric -> median\n",
        "        if df[c].dtype.kind in \"biufc\":\n",
        "            if df[c].isnull().any():\n",
        "                med = pd.concat([X_train_raw[c], X_test_raw[c]]).median()\n",
        "                df[c].fillna(med, inplace=True)\n",
        "        else:\n",
        "            # categorical/text -> string and placeholder for missing\n",
        "            df[c] = df[c].astype(str).fillna(\"NA\").str.strip()\n",
        "\n",
        "#  Frequency encoding for categorical columns\n",
        "combined_for_freq = pd.concat([X_train_raw, X_test_raw], axis=0, ignore_index=True)\n",
        "cat_cols = combined_for_freq.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "for col in cat_cols:\n",
        "    freq = combined_for_freq[col].value_counts(dropna=False)\n",
        "    mapping = freq.to_dict()\n",
        "    X_train_raw[col + \"_freq\"] = X_train_raw[col].map(mapping).fillna(0).astype(int)\n",
        "    X_test_raw[col + \"_freq\"]  = X_test_raw[col].map(mapping).fillna(0).astype(int)\n",
        "\n",
        "# drop original categorical columns\n",
        "X_train_raw = X_train_raw.drop(columns=cat_cols)\n",
        "X_test_raw  = X_test_raw.drop(columns=cat_cols)\n",
        "\n",
        "#  Align features (one-hot fallback then align)\n",
        "full = pd.concat([X_train_raw, X_test_raw], axis=0, ignore_index=True)\n",
        "remaining_cat = full.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "if remaining_cat:\n",
        "    full = pd.get_dummies(full, columns=remaining_cat, drop_first=False)\n",
        "\n",
        "X_all = full.iloc[: len(X_train_raw), :].copy()\n",
        "X_test = full.iloc[len(X_train_raw): , :].copy()\n",
        "X_all, X_test = X_all.align(X_test, join=\"left\", axis=1, fill_value=0)\n",
        "\n",
        "#  Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "#  Train/validation split (stratified)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_all, y, test_size=VALID_SIZE, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "#  Build DMatrix once (reuse for every variant)\n",
        "dtrain = xgb.DMatrix(X_tr, label=y_tr, feature_names=list(X_tr.columns))\n",
        "dval   = xgb.DMatrix(X_val, label=y_val, feature_names=list(X_val.columns))\n",
        "dall   = xgb.DMatrix(X_all, label=y, feature_names=list(X_all.columns))\n",
        "dtest  = xgb.DMatrix(X_test, feature_names=list(X_test.columns))\n",
        "\n",
        "watchlist = [(dtrain, \"train\"), (dval, \"valid\")]\n",
        "\n",
        "#  Base  params for reference\n",
        "base = {\n",
        "    \"objective\": \"multi:softprob\",\n",
        "    \"num_class\": num_classes,\n",
        "    \"eval_metric\": \"mlogloss\",\n",
        "    \"verbosity\": 0,\n",
        "    \"seed\": SEED,\n",
        "    \"tree_method\": \"hist\"\n",
        "}\n",
        "\n",
        "#  16 variant parameter sets (small, guided perturbations)\n",
        "variants = [\n",
        "    # Group 1: learning rate tweaks\n",
        "    {\"eta\": 0.015, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.008, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.012, \"max_depth\": 5, \"subsample\": 0.85, \"colsample_bytree\": 0.75, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "\n",
        "    # Group 2: tree structure\n",
        "    {\"eta\": 0.01, \"max_depth\": 4, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.01, \"max_depth\": 6, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.75, \"colsample_bytree\": 0.8, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.85, \"colsample_bytree\": 0.6, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "\n",
        "    # Group 3: regularization\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.05, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.5},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 4, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "\n",
        "    # Group 4: sampling\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.7, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.9, \"colsample_bytree\": 0.8, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "\n",
        "    # Group 5: eta-depth combos\n",
        "    {\"eta\": 0.007, \"max_depth\": 6, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "    {\"eta\": 0.02, \"max_depth\": 4, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0},\n",
        "\n",
        "    # Group 6: grow policy / booster style\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0, \"grow_policy\": \"lossguide\"},\n",
        "    {\"eta\": 0.01, \"max_depth\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.7, \"min_child_weight\": 3, \"alpha\": 0.01, \"lambda\": 1.0, \"grow_policy\": \"depthwise\"},\n",
        "]\n",
        "\n",
        "# sanity check\n",
        "if len(variants) != 16:\n",
        "    raise RuntimeError(\"Expected 16 variants\")\n",
        "\n",
        "#  Training loop for all variants\n",
        "results = []\n",
        "model_files = []\n",
        "\n",
        "for idx, v in enumerate(variants, start=1):\n",
        "    # build params for xgb.train\n",
        "    p = base.copy()\n",
        "    p.update(v)  # variant overrides base fields\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Running model {idx}/16 with params:\")\n",
        "    print(json.dumps(p, indent=2))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # train on train/val with early stopping\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(\n",
        "        p,\n",
        "        dtrain,\n",
        "        num_boost_round=5000,\n",
        "        evals=watchlist,\n",
        "        early_stopping_rounds=100,\n",
        "        verbose_eval=50\n",
        "    )\n",
        "    t_elapsed = time.time() - t0\n",
        "    best_iter = bst.best_iteration if bst.best_iteration is not None else 5000\n",
        "    print(f\"Model {idx} training done in {t_elapsed:.1f}s, best_iteration={best_iter}\")\n",
        "\n",
        "    # validation accuracy\n",
        "    pred_val = bst.predict(dval)\n",
        "    pred_val_idx = np.argmax(pred_val, axis=1)\n",
        "    val_acc = accuracy_score(y_val, pred_val_idx)\n",
        "    print(f\"Validation accuracy (model {idx}): {val_acc:.5f}\")\n",
        "\n",
        "    # retrain on full data using best_iter\n",
        "    retrain_rounds = best_iter + 1 if best_iter is not None else 5000\n",
        "    print(f\"Retraining model {idx} on full data for {retrain_rounds} rounds...\")\n",
        "    bst_full = xgb.train(p, dall, num_boost_round=retrain_rounds, verbose_eval=50)\n",
        "\n",
        "    # predict on test and save submission\n",
        "    pred_test = bst_full.predict(dtest)\n",
        "    pred_idx = np.argmax(pred_test, axis=1)\n",
        "    pred_labels = le.inverse_transform(pred_idx)\n",
        "\n",
        "    out_name = f\"{OUT_PREFIX}{idx}.csv\"\n",
        "    submission = pd.DataFrame({\"id\": test_ids, \"WeightCategory\": pred_labels})\n",
        "    submission.to_csv(out_name, index=False)\n",
        "    print(f\"Saved submission: {out_name}\")\n",
        "\n",
        "    # record results\n",
        "    results.append({\n",
        "        \"model_idx\": idx,\n",
        "        \"val_accuracy\": float(val_acc),\n",
        "        \"best_iter\": int(best_iter) if best_iter is not None else None,\n",
        "        \"params\": v\n",
        "    })\n",
        "    model_files.append(out_name)\n",
        "\n",
        "# ----------------- Save results CSV -----------------\n",
        "df_results = pd.DataFrame(results)\n",
        "# flatten params column to JSON string for readability\n",
        "df_results[\"params_json\"] = df_results[\"params\"].apply(lambda x: json.dumps(x))\n",
        "df_results = df_results.drop(columns=[\"params\"])\n",
        "df_results = df_results[[\"model_idx\", \"val_accuracy\", \"best_iter\", \"params_json\"]]\n",
        "df_results.to_csv(LOG_CSV, index=False)\n",
        "print(f\"\\nSaved model results to {LOG_CSV}\")\n",
        "print(\"Generated submission files:\", model_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvV2jCkLiCxb",
        "outputId": "b9803829-f419-4455-f9b2-becd6fcc5e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Running model 1/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.015,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.91438\tvalid-mlogloss:1.91491\n",
            "[50]\ttrain-mlogloss:1.04989\tvalid-mlogloss:1.06869\n",
            "[100]\ttrain-mlogloss:0.69987\tvalid-mlogloss:0.72584\n",
            "[150]\ttrain-mlogloss:0.52146\tvalid-mlogloss:0.55216\n",
            "[200]\ttrain-mlogloss:0.42068\tvalid-mlogloss:0.45547\n",
            "[250]\ttrain-mlogloss:0.35840\tvalid-mlogloss:0.39731\n",
            "[300]\ttrain-mlogloss:0.31651\tvalid-mlogloss:0.35967\n",
            "[350]\ttrain-mlogloss:0.28759\tvalid-mlogloss:0.33534\n",
            "[400]\ttrain-mlogloss:0.26699\tvalid-mlogloss:0.31921\n",
            "[450]\ttrain-mlogloss:0.25112\tvalid-mlogloss:0.30773\n",
            "[500]\ttrain-mlogloss:0.23785\tvalid-mlogloss:0.29873\n",
            "[550]\ttrain-mlogloss:0.22690\tvalid-mlogloss:0.29202\n",
            "[600]\ttrain-mlogloss:0.21747\tvalid-mlogloss:0.28682\n",
            "[650]\ttrain-mlogloss:0.20946\tvalid-mlogloss:0.28299\n",
            "[700]\ttrain-mlogloss:0.20209\tvalid-mlogloss:0.27973\n",
            "[750]\ttrain-mlogloss:0.19541\tvalid-mlogloss:0.27715\n",
            "[800]\ttrain-mlogloss:0.18910\tvalid-mlogloss:0.27519\n",
            "[850]\ttrain-mlogloss:0.18328\tvalid-mlogloss:0.27329\n",
            "[900]\ttrain-mlogloss:0.17789\tvalid-mlogloss:0.27184\n",
            "[950]\ttrain-mlogloss:0.17276\tvalid-mlogloss:0.27061\n",
            "[1000]\ttrain-mlogloss:0.16802\tvalid-mlogloss:0.26969\n",
            "[1050]\ttrain-mlogloss:0.16338\tvalid-mlogloss:0.26910\n",
            "[1100]\ttrain-mlogloss:0.15914\tvalid-mlogloss:0.26857\n",
            "[1150]\ttrain-mlogloss:0.15499\tvalid-mlogloss:0.26794\n",
            "[1200]\ttrain-mlogloss:0.15107\tvalid-mlogloss:0.26781\n",
            "[1250]\ttrain-mlogloss:0.14746\tvalid-mlogloss:0.26774\n",
            "[1300]\ttrain-mlogloss:0.14376\tvalid-mlogloss:0.26761\n",
            "[1350]\ttrain-mlogloss:0.14025\tvalid-mlogloss:0.26762\n",
            "[1400]\ttrain-mlogloss:0.13674\tvalid-mlogloss:0.26778\n",
            "[1417]\ttrain-mlogloss:0.13570\tvalid-mlogloss:0.26779\n",
            "Model 1 training done in 31.3s, best_iteration=1317\n",
            "Validation accuracy (model 1): 0.90731\n",
            "Retraining model 1 on full data for 1318 rounds...\n",
            "Saved submission: submission_model_1.csv\n",
            "\n",
            "============================================================\n",
            "Running model 2/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.008,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92725\tvalid-mlogloss:1.92753\n",
            "[50]\ttrain-mlogloss:1.34548\tvalid-mlogloss:1.35799\n",
            "[100]\ttrain-mlogloss:1.02188\tvalid-mlogloss:1.04096\n",
            "[150]\ttrain-mlogloss:0.81353\tvalid-mlogloss:0.83671\n",
            "[200]\ttrain-mlogloss:0.67246\tvalid-mlogloss:0.69879\n",
            "[250]\ttrain-mlogloss:0.57233\tvalid-mlogloss:0.60144\n",
            "[300]\ttrain-mlogloss:0.49840\tvalid-mlogloss:0.52999\n",
            "[350]\ttrain-mlogloss:0.44396\tvalid-mlogloss:0.47763\n",
            "[400]\ttrain-mlogloss:0.40266\tvalid-mlogloss:0.43844\n",
            "[450]\ttrain-mlogloss:0.37068\tvalid-mlogloss:0.40865\n",
            "[500]\ttrain-mlogloss:0.34436\tvalid-mlogloss:0.38443\n",
            "[550]\ttrain-mlogloss:0.32319\tvalid-mlogloss:0.36568\n",
            "[600]\ttrain-mlogloss:0.30567\tvalid-mlogloss:0.35055\n",
            "[650]\ttrain-mlogloss:0.29104\tvalid-mlogloss:0.33825\n",
            "[700]\ttrain-mlogloss:0.27828\tvalid-mlogloss:0.32789\n",
            "[750]\ttrain-mlogloss:0.26742\tvalid-mlogloss:0.31928\n",
            "[800]\ttrain-mlogloss:0.25810\tvalid-mlogloss:0.31236\n",
            "[850]\ttrain-mlogloss:0.25003\tvalid-mlogloss:0.30638\n",
            "[900]\ttrain-mlogloss:0.24284\tvalid-mlogloss:0.30146\n",
            "[950]\ttrain-mlogloss:0.23637\tvalid-mlogloss:0.29709\n",
            "[1000]\ttrain-mlogloss:0.23046\tvalid-mlogloss:0.29349\n",
            "[1050]\ttrain-mlogloss:0.22505\tvalid-mlogloss:0.29043\n",
            "[1100]\ttrain-mlogloss:0.22010\tvalid-mlogloss:0.28782\n",
            "[1150]\ttrain-mlogloss:0.21552\tvalid-mlogloss:0.28526\n",
            "[1200]\ttrain-mlogloss:0.21114\tvalid-mlogloss:0.28310\n",
            "[1250]\ttrain-mlogloss:0.20710\tvalid-mlogloss:0.28139\n",
            "[1300]\ttrain-mlogloss:0.20326\tvalid-mlogloss:0.27976\n",
            "[1350]\ttrain-mlogloss:0.19949\tvalid-mlogloss:0.27830\n",
            "[1400]\ttrain-mlogloss:0.19583\tvalid-mlogloss:0.27712\n",
            "[1450]\ttrain-mlogloss:0.19246\tvalid-mlogloss:0.27596\n",
            "[1500]\ttrain-mlogloss:0.18928\tvalid-mlogloss:0.27499\n",
            "[1550]\ttrain-mlogloss:0.18621\tvalid-mlogloss:0.27386\n",
            "[1600]\ttrain-mlogloss:0.18323\tvalid-mlogloss:0.27314\n",
            "[1650]\ttrain-mlogloss:0.18037\tvalid-mlogloss:0.27241\n",
            "[1700]\ttrain-mlogloss:0.17764\tvalid-mlogloss:0.27175\n",
            "[1750]\ttrain-mlogloss:0.17490\tvalid-mlogloss:0.27106\n",
            "[1800]\ttrain-mlogloss:0.17218\tvalid-mlogloss:0.27060\n",
            "[1850]\ttrain-mlogloss:0.16962\tvalid-mlogloss:0.27010\n",
            "[1900]\ttrain-mlogloss:0.16691\tvalid-mlogloss:0.26962\n",
            "[1950]\ttrain-mlogloss:0.16455\tvalid-mlogloss:0.26930\n",
            "[2000]\ttrain-mlogloss:0.16219\tvalid-mlogloss:0.26900\n",
            "[2050]\ttrain-mlogloss:0.15992\tvalid-mlogloss:0.26865\n",
            "[2100]\ttrain-mlogloss:0.15759\tvalid-mlogloss:0.26840\n",
            "[2150]\ttrain-mlogloss:0.15539\tvalid-mlogloss:0.26828\n",
            "[2200]\ttrain-mlogloss:0.15320\tvalid-mlogloss:0.26812\n",
            "[2250]\ttrain-mlogloss:0.15112\tvalid-mlogloss:0.26803\n",
            "[2300]\ttrain-mlogloss:0.14906\tvalid-mlogloss:0.26802\n",
            "[2350]\ttrain-mlogloss:0.14708\tvalid-mlogloss:0.26788\n",
            "[2400]\ttrain-mlogloss:0.14511\tvalid-mlogloss:0.26784\n",
            "[2450]\ttrain-mlogloss:0.14324\tvalid-mlogloss:0.26777\n",
            "[2500]\ttrain-mlogloss:0.14139\tvalid-mlogloss:0.26775\n",
            "[2550]\ttrain-mlogloss:0.13960\tvalid-mlogloss:0.26776\n",
            "[2577]\ttrain-mlogloss:0.13860\tvalid-mlogloss:0.26772\n",
            "Model 2 training done in 40.5s, best_iteration=2477\n",
            "Validation accuracy (model 2): 0.90570\n",
            "Retraining model 2 on full data for 2478 rounds...\n",
            "Saved submission: submission_model_2.csv\n",
            "\n",
            "============================================================\n",
            "Running model 3/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.012,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.85,\n",
            "  \"colsample_bytree\": 0.75,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.91976\tvalid-mlogloss:1.92004\n",
            "[50]\ttrain-mlogloss:1.14781\tvalid-mlogloss:1.16439\n",
            "[100]\ttrain-mlogloss:0.79891\tvalid-mlogloss:0.82246\n",
            "[150]\ttrain-mlogloss:0.60224\tvalid-mlogloss:0.63004\n",
            "[200]\ttrain-mlogloss:0.48711\tvalid-mlogloss:0.51898\n",
            "[250]\ttrain-mlogloss:0.41198\tvalid-mlogloss:0.44723\n",
            "[300]\ttrain-mlogloss:0.36111\tvalid-mlogloss:0.39964\n",
            "[350]\ttrain-mlogloss:0.32554\tvalid-mlogloss:0.36765\n",
            "[400]\ttrain-mlogloss:0.29927\tvalid-mlogloss:0.34509\n",
            "[450]\ttrain-mlogloss:0.27958\tvalid-mlogloss:0.32922\n",
            "[500]\ttrain-mlogloss:0.26365\tvalid-mlogloss:0.31707\n",
            "[550]\ttrain-mlogloss:0.25077\tvalid-mlogloss:0.30795\n",
            "[600]\ttrain-mlogloss:0.23990\tvalid-mlogloss:0.30085\n",
            "[650]\ttrain-mlogloss:0.23058\tvalid-mlogloss:0.29522\n",
            "[700]\ttrain-mlogloss:0.22260\tvalid-mlogloss:0.29076\n",
            "[750]\ttrain-mlogloss:0.21543\tvalid-mlogloss:0.28703\n",
            "[800]\ttrain-mlogloss:0.20898\tvalid-mlogloss:0.28403\n",
            "[850]\ttrain-mlogloss:0.20283\tvalid-mlogloss:0.28136\n",
            "[900]\ttrain-mlogloss:0.19714\tvalid-mlogloss:0.27891\n",
            "[950]\ttrain-mlogloss:0.19184\tvalid-mlogloss:0.27687\n",
            "[1000]\ttrain-mlogloss:0.18688\tvalid-mlogloss:0.27545\n",
            "[1050]\ttrain-mlogloss:0.18211\tvalid-mlogloss:0.27417\n",
            "[1100]\ttrain-mlogloss:0.17770\tvalid-mlogloss:0.27302\n",
            "[1150]\ttrain-mlogloss:0.17350\tvalid-mlogloss:0.27212\n",
            "[1200]\ttrain-mlogloss:0.16950\tvalid-mlogloss:0.27136\n",
            "[1250]\ttrain-mlogloss:0.16582\tvalid-mlogloss:0.27091\n",
            "[1300]\ttrain-mlogloss:0.16199\tvalid-mlogloss:0.27027\n",
            "[1350]\ttrain-mlogloss:0.15850\tvalid-mlogloss:0.26991\n",
            "[1400]\ttrain-mlogloss:0.15491\tvalid-mlogloss:0.26949\n",
            "[1450]\ttrain-mlogloss:0.15165\tvalid-mlogloss:0.26920\n",
            "[1500]\ttrain-mlogloss:0.14850\tvalid-mlogloss:0.26905\n",
            "[1550]\ttrain-mlogloss:0.14552\tvalid-mlogloss:0.26896\n",
            "[1600]\ttrain-mlogloss:0.14254\tvalid-mlogloss:0.26877\n",
            "[1650]\ttrain-mlogloss:0.13981\tvalid-mlogloss:0.26884\n",
            "[1700]\ttrain-mlogloss:0.13709\tvalid-mlogloss:0.26876\n",
            "[1750]\ttrain-mlogloss:0.13443\tvalid-mlogloss:0.26885\n",
            "[1773]\ttrain-mlogloss:0.13322\tvalid-mlogloss:0.26892\n",
            "Model 3 training done in 28.1s, best_iteration=1673\n",
            "Validation accuracy (model 3): 0.90602\n",
            "Retraining model 3 on full data for 1674 rounds...\n",
            "Saved submission: submission_model_3.csv\n",
            "\n",
            "============================================================\n",
            "Running model 4/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 4,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92461\tvalid-mlogloss:1.92482\n",
            "[50]\ttrain-mlogloss:1.28697\tvalid-mlogloss:1.29742\n",
            "[100]\ttrain-mlogloss:0.96314\tvalid-mlogloss:0.97792\n",
            "[150]\ttrain-mlogloss:0.76437\tvalid-mlogloss:0.78166\n",
            "[200]\ttrain-mlogloss:0.63403\tvalid-mlogloss:0.65344\n",
            "[250]\ttrain-mlogloss:0.54439\tvalid-mlogloss:0.56542\n",
            "[300]\ttrain-mlogloss:0.47873\tvalid-mlogloss:0.50136\n",
            "[350]\ttrain-mlogloss:0.42999\tvalid-mlogloss:0.45431\n",
            "[400]\ttrain-mlogloss:0.39446\tvalid-mlogloss:0.42069\n",
            "[450]\ttrain-mlogloss:0.36688\tvalid-mlogloss:0.39482\n",
            "[500]\ttrain-mlogloss:0.34398\tvalid-mlogloss:0.37353\n",
            "[550]\ttrain-mlogloss:0.32552\tvalid-mlogloss:0.35702\n",
            "[600]\ttrain-mlogloss:0.31030\tvalid-mlogloss:0.34382\n",
            "[650]\ttrain-mlogloss:0.29750\tvalid-mlogloss:0.33304\n",
            "[700]\ttrain-mlogloss:0.28681\tvalid-mlogloss:0.32443\n",
            "[750]\ttrain-mlogloss:0.27750\tvalid-mlogloss:0.31706\n",
            "[800]\ttrain-mlogloss:0.26957\tvalid-mlogloss:0.31102\n",
            "[850]\ttrain-mlogloss:0.26241\tvalid-mlogloss:0.30567\n",
            "[900]\ttrain-mlogloss:0.25609\tvalid-mlogloss:0.30119\n",
            "[950]\ttrain-mlogloss:0.25029\tvalid-mlogloss:0.29707\n",
            "[1000]\ttrain-mlogloss:0.24492\tvalid-mlogloss:0.29367\n",
            "[1050]\ttrain-mlogloss:0.24005\tvalid-mlogloss:0.29077\n",
            "[1100]\ttrain-mlogloss:0.23546\tvalid-mlogloss:0.28819\n",
            "[1150]\ttrain-mlogloss:0.23123\tvalid-mlogloss:0.28578\n",
            "[1200]\ttrain-mlogloss:0.22709\tvalid-mlogloss:0.28369\n",
            "[1250]\ttrain-mlogloss:0.22336\tvalid-mlogloss:0.28214\n",
            "[1300]\ttrain-mlogloss:0.21974\tvalid-mlogloss:0.28047\n",
            "[1350]\ttrain-mlogloss:0.21609\tvalid-mlogloss:0.27888\n",
            "[1400]\ttrain-mlogloss:0.21257\tvalid-mlogloss:0.27758\n",
            "[1450]\ttrain-mlogloss:0.20941\tvalid-mlogloss:0.27641\n",
            "[1500]\ttrain-mlogloss:0.20654\tvalid-mlogloss:0.27531\n",
            "[1550]\ttrain-mlogloss:0.20369\tvalid-mlogloss:0.27421\n",
            "[1600]\ttrain-mlogloss:0.20095\tvalid-mlogloss:0.27338\n",
            "[1650]\ttrain-mlogloss:0.19833\tvalid-mlogloss:0.27256\n",
            "[1700]\ttrain-mlogloss:0.19579\tvalid-mlogloss:0.27180\n",
            "[1750]\ttrain-mlogloss:0.19337\tvalid-mlogloss:0.27111\n",
            "[1800]\ttrain-mlogloss:0.19079\tvalid-mlogloss:0.27048\n",
            "[1850]\ttrain-mlogloss:0.18841\tvalid-mlogloss:0.26994\n",
            "[1900]\ttrain-mlogloss:0.18594\tvalid-mlogloss:0.26931\n",
            "[1950]\ttrain-mlogloss:0.18374\tvalid-mlogloss:0.26889\n",
            "[2000]\ttrain-mlogloss:0.18156\tvalid-mlogloss:0.26854\n",
            "[2050]\ttrain-mlogloss:0.17941\tvalid-mlogloss:0.26819\n",
            "[2100]\ttrain-mlogloss:0.17725\tvalid-mlogloss:0.26785\n",
            "[2150]\ttrain-mlogloss:0.17524\tvalid-mlogloss:0.26748\n",
            "[2200]\ttrain-mlogloss:0.17325\tvalid-mlogloss:0.26716\n",
            "[2250]\ttrain-mlogloss:0.17125\tvalid-mlogloss:0.26702\n",
            "[2300]\ttrain-mlogloss:0.16934\tvalid-mlogloss:0.26681\n",
            "[2350]\ttrain-mlogloss:0.16749\tvalid-mlogloss:0.26653\n",
            "[2400]\ttrain-mlogloss:0.16566\tvalid-mlogloss:0.26642\n",
            "[2450]\ttrain-mlogloss:0.16391\tvalid-mlogloss:0.26632\n",
            "[2500]\ttrain-mlogloss:0.16217\tvalid-mlogloss:0.26622\n",
            "[2550]\ttrain-mlogloss:0.16047\tvalid-mlogloss:0.26611\n",
            "[2600]\ttrain-mlogloss:0.15879\tvalid-mlogloss:0.26595\n",
            "[2650]\ttrain-mlogloss:0.15720\tvalid-mlogloss:0.26604\n",
            "[2699]\ttrain-mlogloss:0.15564\tvalid-mlogloss:0.26597\n",
            "Model 4 training done in 43.6s, best_iteration=2600\n",
            "Validation accuracy (model 4): 0.90698\n",
            "Retraining model 4 on full data for 2601 rounds...\n",
            "Saved submission: submission_model_4.csv\n",
            "\n",
            "============================================================\n",
            "Running model 5/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 6,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92279\tvalid-mlogloss:1.92327\n",
            "[50]\ttrain-mlogloss:1.22068\tvalid-mlogloss:1.23874\n",
            "[100]\ttrain-mlogloss:0.86983\tvalid-mlogloss:0.89760\n",
            "[150]\ttrain-mlogloss:0.66083\tvalid-mlogloss:0.69469\n",
            "[200]\ttrain-mlogloss:0.52867\tvalid-mlogloss:0.56801\n",
            "[250]\ttrain-mlogloss:0.44051\tvalid-mlogloss:0.48474\n",
            "[300]\ttrain-mlogloss:0.37845\tvalid-mlogloss:0.42702\n",
            "[350]\ttrain-mlogloss:0.33506\tvalid-mlogloss:0.38798\n",
            "[400]\ttrain-mlogloss:0.30382\tvalid-mlogloss:0.36076\n",
            "[450]\ttrain-mlogloss:0.27998\tvalid-mlogloss:0.34100\n",
            "[500]\ttrain-mlogloss:0.26053\tvalid-mlogloss:0.32546\n",
            "[550]\ttrain-mlogloss:0.24506\tvalid-mlogloss:0.31428\n",
            "[600]\ttrain-mlogloss:0.23220\tvalid-mlogloss:0.30545\n",
            "[650]\ttrain-mlogloss:0.22154\tvalid-mlogloss:0.29859\n",
            "[700]\ttrain-mlogloss:0.21207\tvalid-mlogloss:0.29309\n",
            "[750]\ttrain-mlogloss:0.20384\tvalid-mlogloss:0.28840\n",
            "[800]\ttrain-mlogloss:0.19650\tvalid-mlogloss:0.28479\n",
            "[850]\ttrain-mlogloss:0.18992\tvalid-mlogloss:0.28178\n",
            "[900]\ttrain-mlogloss:0.18394\tvalid-mlogloss:0.27925\n",
            "[950]\ttrain-mlogloss:0.17857\tvalid-mlogloss:0.27707\n",
            "[1000]\ttrain-mlogloss:0.17345\tvalid-mlogloss:0.27535\n",
            "[1050]\ttrain-mlogloss:0.16873\tvalid-mlogloss:0.27392\n",
            "[1100]\ttrain-mlogloss:0.16423\tvalid-mlogloss:0.27270\n",
            "[1150]\ttrain-mlogloss:0.16009\tvalid-mlogloss:0.27164\n",
            "[1200]\ttrain-mlogloss:0.15600\tvalid-mlogloss:0.27086\n",
            "[1250]\ttrain-mlogloss:0.15216\tvalid-mlogloss:0.27029\n",
            "[1300]\ttrain-mlogloss:0.14834\tvalid-mlogloss:0.26972\n",
            "[1350]\ttrain-mlogloss:0.14470\tvalid-mlogloss:0.26937\n",
            "[1400]\ttrain-mlogloss:0.14099\tvalid-mlogloss:0.26929\n",
            "[1450]\ttrain-mlogloss:0.13771\tvalid-mlogloss:0.26908\n",
            "[1500]\ttrain-mlogloss:0.13456\tvalid-mlogloss:0.26878\n",
            "[1550]\ttrain-mlogloss:0.13143\tvalid-mlogloss:0.26875\n",
            "[1600]\ttrain-mlogloss:0.12845\tvalid-mlogloss:0.26871\n",
            "[1650]\ttrain-mlogloss:0.12567\tvalid-mlogloss:0.26891\n",
            "[1695]\ttrain-mlogloss:0.12322\tvalid-mlogloss:0.26901\n",
            "Model 5 training done in 31.1s, best_iteration=1595\n",
            "Validation accuracy (model 5): 0.90602\n",
            "Retraining model 5 on full data for 1596 rounds...\n",
            "Saved submission: submission_model_5.csv\n",
            "\n",
            "============================================================\n",
            "Running model 6/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.75,\n",
            "  \"colsample_bytree\": 0.8,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92343\tvalid-mlogloss:1.92369\n",
            "[50]\ttrain-mlogloss:1.23538\tvalid-mlogloss:1.24985\n",
            "[100]\ttrain-mlogloss:0.89389\tvalid-mlogloss:0.91502\n",
            "[150]\ttrain-mlogloss:0.68809\tvalid-mlogloss:0.71301\n",
            "[200]\ttrain-mlogloss:0.56056\tvalid-mlogloss:0.58891\n",
            "[250]\ttrain-mlogloss:0.47337\tvalid-mlogloss:0.50467\n",
            "[300]\ttrain-mlogloss:0.41248\tvalid-mlogloss:0.44627\n",
            "[350]\ttrain-mlogloss:0.36931\tvalid-mlogloss:0.40579\n",
            "[400]\ttrain-mlogloss:0.33724\tvalid-mlogloss:0.37656\n",
            "[450]\ttrain-mlogloss:0.31285\tvalid-mlogloss:0.35522\n",
            "[500]\ttrain-mlogloss:0.29311\tvalid-mlogloss:0.33863\n",
            "[550]\ttrain-mlogloss:0.27723\tvalid-mlogloss:0.32601\n",
            "[600]\ttrain-mlogloss:0.26420\tvalid-mlogloss:0.31592\n",
            "[650]\ttrain-mlogloss:0.25346\tvalid-mlogloss:0.30819\n",
            "[700]\ttrain-mlogloss:0.24386\tvalid-mlogloss:0.30180\n",
            "[750]\ttrain-mlogloss:0.23552\tvalid-mlogloss:0.29646\n",
            "[800]\ttrain-mlogloss:0.22837\tvalid-mlogloss:0.29223\n",
            "[850]\ttrain-mlogloss:0.22175\tvalid-mlogloss:0.28853\n",
            "[900]\ttrain-mlogloss:0.21572\tvalid-mlogloss:0.28558\n",
            "[950]\ttrain-mlogloss:0.21033\tvalid-mlogloss:0.28301\n",
            "[1000]\ttrain-mlogloss:0.20510\tvalid-mlogloss:0.28088\n",
            "[1050]\ttrain-mlogloss:0.20033\tvalid-mlogloss:0.27904\n",
            "[1100]\ttrain-mlogloss:0.19571\tvalid-mlogloss:0.27731\n",
            "[1150]\ttrain-mlogloss:0.19143\tvalid-mlogloss:0.27593\n",
            "[1200]\ttrain-mlogloss:0.18722\tvalid-mlogloss:0.27463\n",
            "[1250]\ttrain-mlogloss:0.18336\tvalid-mlogloss:0.27360\n",
            "[1300]\ttrain-mlogloss:0.17962\tvalid-mlogloss:0.27272\n",
            "[1350]\ttrain-mlogloss:0.17602\tvalid-mlogloss:0.27189\n",
            "[1400]\ttrain-mlogloss:0.17250\tvalid-mlogloss:0.27122\n",
            "[1450]\ttrain-mlogloss:0.16921\tvalid-mlogloss:0.27058\n",
            "[1500]\ttrain-mlogloss:0.16603\tvalid-mlogloss:0.27011\n",
            "[1550]\ttrain-mlogloss:0.16294\tvalid-mlogloss:0.26958\n",
            "[1600]\ttrain-mlogloss:0.15997\tvalid-mlogloss:0.26920\n",
            "[1650]\ttrain-mlogloss:0.15716\tvalid-mlogloss:0.26893\n",
            "[1700]\ttrain-mlogloss:0.15444\tvalid-mlogloss:0.26878\n",
            "[1750]\ttrain-mlogloss:0.15179\tvalid-mlogloss:0.26846\n",
            "[1800]\ttrain-mlogloss:0.14910\tvalid-mlogloss:0.26836\n",
            "[1850]\ttrain-mlogloss:0.14662\tvalid-mlogloss:0.26821\n",
            "[1900]\ttrain-mlogloss:0.14400\tvalid-mlogloss:0.26809\n",
            "[1950]\ttrain-mlogloss:0.14163\tvalid-mlogloss:0.26822\n",
            "[2000]\ttrain-mlogloss:0.13916\tvalid-mlogloss:0.26836\n",
            "[2007]\ttrain-mlogloss:0.13883\tvalid-mlogloss:0.26834\n",
            "Model 6 training done in 33.1s, best_iteration=1907\n",
            "Validation accuracy (model 6): 0.90634\n",
            "Retraining model 6 on full data for 1908 rounds...\n",
            "Saved submission: submission_model_6.csv\n",
            "\n",
            "============================================================\n",
            "Running model 7/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.85,\n",
            "  \"colsample_bytree\": 0.6,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92407\tvalid-mlogloss:1.92437\n",
            "[50]\ttrain-mlogloss:1.29002\tvalid-mlogloss:1.30432\n",
            "[100]\ttrain-mlogloss:0.95310\tvalid-mlogloss:0.97516\n",
            "[150]\ttrain-mlogloss:0.74807\tvalid-mlogloss:0.77472\n",
            "[200]\ttrain-mlogloss:0.61333\tvalid-mlogloss:0.64357\n",
            "[250]\ttrain-mlogloss:0.51830\tvalid-mlogloss:0.55181\n",
            "[300]\ttrain-mlogloss:0.45053\tvalid-mlogloss:0.48683\n",
            "[350]\ttrain-mlogloss:0.40262\tvalid-mlogloss:0.44148\n",
            "[400]\ttrain-mlogloss:0.36597\tvalid-mlogloss:0.40729\n",
            "[450]\ttrain-mlogloss:0.33804\tvalid-mlogloss:0.38192\n",
            "[500]\ttrain-mlogloss:0.31544\tvalid-mlogloss:0.36189\n",
            "[550]\ttrain-mlogloss:0.29680\tvalid-mlogloss:0.34576\n",
            "[600]\ttrain-mlogloss:0.28135\tvalid-mlogloss:0.33294\n",
            "[650]\ttrain-mlogloss:0.26845\tvalid-mlogloss:0.32257\n",
            "[700]\ttrain-mlogloss:0.25739\tvalid-mlogloss:0.31408\n",
            "[750]\ttrain-mlogloss:0.24776\tvalid-mlogloss:0.30697\n",
            "[800]\ttrain-mlogloss:0.23939\tvalid-mlogloss:0.30111\n",
            "[850]\ttrain-mlogloss:0.23197\tvalid-mlogloss:0.29613\n",
            "[900]\ttrain-mlogloss:0.22506\tvalid-mlogloss:0.29192\n",
            "[950]\ttrain-mlogloss:0.21900\tvalid-mlogloss:0.28843\n",
            "[1000]\ttrain-mlogloss:0.21339\tvalid-mlogloss:0.28527\n",
            "[1050]\ttrain-mlogloss:0.20827\tvalid-mlogloss:0.28251\n",
            "[1100]\ttrain-mlogloss:0.20364\tvalid-mlogloss:0.28038\n",
            "[1150]\ttrain-mlogloss:0.19921\tvalid-mlogloss:0.27828\n",
            "[1200]\ttrain-mlogloss:0.19500\tvalid-mlogloss:0.27655\n",
            "[1250]\ttrain-mlogloss:0.19126\tvalid-mlogloss:0.27514\n",
            "[1300]\ttrain-mlogloss:0.18764\tvalid-mlogloss:0.27394\n",
            "[1350]\ttrain-mlogloss:0.18409\tvalid-mlogloss:0.27276\n",
            "[1400]\ttrain-mlogloss:0.18067\tvalid-mlogloss:0.27170\n",
            "[1450]\ttrain-mlogloss:0.17752\tvalid-mlogloss:0.27081\n",
            "[1500]\ttrain-mlogloss:0.17444\tvalid-mlogloss:0.27012\n",
            "[1550]\ttrain-mlogloss:0.17140\tvalid-mlogloss:0.26943\n",
            "[1600]\ttrain-mlogloss:0.16846\tvalid-mlogloss:0.26883\n",
            "[1650]\ttrain-mlogloss:0.16573\tvalid-mlogloss:0.26833\n",
            "[1700]\ttrain-mlogloss:0.16297\tvalid-mlogloss:0.26784\n",
            "[1750]\ttrain-mlogloss:0.16027\tvalid-mlogloss:0.26746\n",
            "[1800]\ttrain-mlogloss:0.15761\tvalid-mlogloss:0.26725\n",
            "[1850]\ttrain-mlogloss:0.15509\tvalid-mlogloss:0.26689\n",
            "[1900]\ttrain-mlogloss:0.15253\tvalid-mlogloss:0.26645\n",
            "[1950]\ttrain-mlogloss:0.15016\tvalid-mlogloss:0.26615\n",
            "[2000]\ttrain-mlogloss:0.14787\tvalid-mlogloss:0.26602\n",
            "[2050]\ttrain-mlogloss:0.14560\tvalid-mlogloss:0.26592\n",
            "[2100]\ttrain-mlogloss:0.14335\tvalid-mlogloss:0.26574\n",
            "[2150]\ttrain-mlogloss:0.14119\tvalid-mlogloss:0.26581\n",
            "[2198]\ttrain-mlogloss:0.13922\tvalid-mlogloss:0.26581\n",
            "Model 7 training done in 37.8s, best_iteration=2099\n",
            "Validation accuracy (model 7): 0.90473\n",
            "Retraining model 7 on full data for 2100 rounds...\n",
            "Saved submission: submission_model_7.csv\n",
            "\n",
            "============================================================\n",
            "Running model 8/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.05,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92357\tvalid-mlogloss:1.92392\n",
            "[50]\ttrain-mlogloss:1.24803\tvalid-mlogloss:1.26265\n",
            "[100]\ttrain-mlogloss:0.90695\tvalid-mlogloss:0.92830\n",
            "[150]\ttrain-mlogloss:0.70245\tvalid-mlogloss:0.72794\n",
            "[200]\ttrain-mlogloss:0.57237\tvalid-mlogloss:0.60140\n",
            "[250]\ttrain-mlogloss:0.48403\tvalid-mlogloss:0.51617\n",
            "[300]\ttrain-mlogloss:0.42119\tvalid-mlogloss:0.45587\n",
            "[350]\ttrain-mlogloss:0.37654\tvalid-mlogloss:0.41374\n",
            "[400]\ttrain-mlogloss:0.34409\tvalid-mlogloss:0.38395\n",
            "[450]\ttrain-mlogloss:0.31882\tvalid-mlogloss:0.36155\n",
            "[500]\ttrain-mlogloss:0.29810\tvalid-mlogloss:0.34369\n",
            "[550]\ttrain-mlogloss:0.28176\tvalid-mlogloss:0.33029\n",
            "[600]\ttrain-mlogloss:0.26814\tvalid-mlogloss:0.31957\n",
            "[650]\ttrain-mlogloss:0.25666\tvalid-mlogloss:0.31121\n",
            "[700]\ttrain-mlogloss:0.24673\tvalid-mlogloss:0.30442\n",
            "[750]\ttrain-mlogloss:0.23817\tvalid-mlogloss:0.29861\n",
            "[800]\ttrain-mlogloss:0.23074\tvalid-mlogloss:0.29400\n",
            "[850]\ttrain-mlogloss:0.22404\tvalid-mlogloss:0.28984\n",
            "[900]\ttrain-mlogloss:0.21804\tvalid-mlogloss:0.28646\n",
            "[950]\ttrain-mlogloss:0.21255\tvalid-mlogloss:0.28343\n",
            "[1000]\ttrain-mlogloss:0.20734\tvalid-mlogloss:0.28103\n",
            "[1050]\ttrain-mlogloss:0.20269\tvalid-mlogloss:0.27911\n",
            "[1100]\ttrain-mlogloss:0.19824\tvalid-mlogloss:0.27738\n",
            "[1150]\ttrain-mlogloss:0.19408\tvalid-mlogloss:0.27583\n",
            "[1200]\ttrain-mlogloss:0.18999\tvalid-mlogloss:0.27448\n",
            "[1250]\ttrain-mlogloss:0.18616\tvalid-mlogloss:0.27347\n",
            "[1300]\ttrain-mlogloss:0.18240\tvalid-mlogloss:0.27246\n",
            "[1350]\ttrain-mlogloss:0.17871\tvalid-mlogloss:0.27159\n",
            "[1400]\ttrain-mlogloss:0.17503\tvalid-mlogloss:0.27093\n",
            "[1450]\ttrain-mlogloss:0.17179\tvalid-mlogloss:0.27031\n",
            "[1500]\ttrain-mlogloss:0.16865\tvalid-mlogloss:0.26968\n",
            "[1550]\ttrain-mlogloss:0.16560\tvalid-mlogloss:0.26914\n",
            "[1600]\ttrain-mlogloss:0.16263\tvalid-mlogloss:0.26877\n",
            "[1650]\ttrain-mlogloss:0.15986\tvalid-mlogloss:0.26847\n",
            "[1700]\ttrain-mlogloss:0.15711\tvalid-mlogloss:0.26807\n",
            "[1750]\ttrain-mlogloss:0.15441\tvalid-mlogloss:0.26779\n",
            "[1800]\ttrain-mlogloss:0.15174\tvalid-mlogloss:0.26764\n",
            "[1850]\ttrain-mlogloss:0.14919\tvalid-mlogloss:0.26748\n",
            "[1900]\ttrain-mlogloss:0.14655\tvalid-mlogloss:0.26731\n",
            "[1950]\ttrain-mlogloss:0.14425\tvalid-mlogloss:0.26719\n",
            "[2000]\ttrain-mlogloss:0.14189\tvalid-mlogloss:0.26722\n",
            "[2050]\ttrain-mlogloss:0.13963\tvalid-mlogloss:0.26717\n",
            "[2100]\ttrain-mlogloss:0.13732\tvalid-mlogloss:0.26726\n",
            "[2139]\ttrain-mlogloss:0.13564\tvalid-mlogloss:0.26736\n",
            "Model 8 training done in 32.1s, best_iteration=2040\n",
            "Validation accuracy (model 8): 0.90602\n",
            "Retraining model 8 on full data for 2041 rounds...\n",
            "Saved submission: submission_model_8.csv\n",
            "\n",
            "============================================================\n",
            "Running model 9/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.5\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92367\tvalid-mlogloss:1.92401\n",
            "[50]\ttrain-mlogloss:1.24989\tvalid-mlogloss:1.26445\n",
            "[100]\ttrain-mlogloss:0.90899\tvalid-mlogloss:0.93016\n",
            "[150]\ttrain-mlogloss:0.70438\tvalid-mlogloss:0.72958\n",
            "[200]\ttrain-mlogloss:0.57428\tvalid-mlogloss:0.60291\n",
            "[250]\ttrain-mlogloss:0.48588\tvalid-mlogloss:0.51754\n",
            "[300]\ttrain-mlogloss:0.42301\tvalid-mlogloss:0.45711\n",
            "[350]\ttrain-mlogloss:0.37828\tvalid-mlogloss:0.41477\n",
            "[400]\ttrain-mlogloss:0.34584\tvalid-mlogloss:0.38495\n",
            "[450]\ttrain-mlogloss:0.32056\tvalid-mlogloss:0.36254\n",
            "[500]\ttrain-mlogloss:0.29991\tvalid-mlogloss:0.34468\n",
            "[550]\ttrain-mlogloss:0.28360\tvalid-mlogloss:0.33117\n",
            "[600]\ttrain-mlogloss:0.27001\tvalid-mlogloss:0.32042\n",
            "[650]\ttrain-mlogloss:0.25848\tvalid-mlogloss:0.31198\n",
            "[700]\ttrain-mlogloss:0.24867\tvalid-mlogloss:0.30515\n",
            "[750]\ttrain-mlogloss:0.24012\tvalid-mlogloss:0.29934\n",
            "[800]\ttrain-mlogloss:0.23268\tvalid-mlogloss:0.29464\n",
            "[850]\ttrain-mlogloss:0.22600\tvalid-mlogloss:0.29041\n",
            "[900]\ttrain-mlogloss:0.21999\tvalid-mlogloss:0.28702\n",
            "[950]\ttrain-mlogloss:0.21451\tvalid-mlogloss:0.28394\n",
            "[1000]\ttrain-mlogloss:0.20940\tvalid-mlogloss:0.28156\n",
            "[1050]\ttrain-mlogloss:0.20479\tvalid-mlogloss:0.27966\n",
            "[1100]\ttrain-mlogloss:0.20031\tvalid-mlogloss:0.27799\n",
            "[1150]\ttrain-mlogloss:0.19613\tvalid-mlogloss:0.27640\n",
            "[1200]\ttrain-mlogloss:0.19209\tvalid-mlogloss:0.27504\n",
            "[1250]\ttrain-mlogloss:0.18832\tvalid-mlogloss:0.27406\n",
            "[1300]\ttrain-mlogloss:0.18460\tvalid-mlogloss:0.27295\n",
            "[1350]\ttrain-mlogloss:0.18094\tvalid-mlogloss:0.27209\n",
            "[1400]\ttrain-mlogloss:0.17735\tvalid-mlogloss:0.27146\n",
            "[1450]\ttrain-mlogloss:0.17416\tvalid-mlogloss:0.27080\n",
            "[1500]\ttrain-mlogloss:0.17111\tvalid-mlogloss:0.27021\n",
            "[1550]\ttrain-mlogloss:0.16817\tvalid-mlogloss:0.26964\n",
            "[1600]\ttrain-mlogloss:0.16527\tvalid-mlogloss:0.26922\n",
            "[1650]\ttrain-mlogloss:0.16251\tvalid-mlogloss:0.26885\n",
            "[1700]\ttrain-mlogloss:0.15978\tvalid-mlogloss:0.26843\n",
            "[1750]\ttrain-mlogloss:0.15714\tvalid-mlogloss:0.26814\n",
            "[1800]\ttrain-mlogloss:0.15450\tvalid-mlogloss:0.26797\n",
            "[1850]\ttrain-mlogloss:0.15202\tvalid-mlogloss:0.26779\n",
            "[1900]\ttrain-mlogloss:0.14938\tvalid-mlogloss:0.26763\n",
            "[1950]\ttrain-mlogloss:0.14708\tvalid-mlogloss:0.26746\n",
            "[2000]\ttrain-mlogloss:0.14474\tvalid-mlogloss:0.26751\n",
            "[2050]\ttrain-mlogloss:0.14251\tvalid-mlogloss:0.26745\n",
            "[2100]\ttrain-mlogloss:0.14020\tvalid-mlogloss:0.26747\n",
            "[2132]\ttrain-mlogloss:0.13883\tvalid-mlogloss:0.26754\n",
            "Model 9 training done in 32.1s, best_iteration=2033\n",
            "Validation accuracy (model 9): 0.90602\n",
            "Retraining model 9 on full data for 2034 rounds...\n",
            "Saved submission: submission_model_9.csv\n",
            "\n",
            "============================================================\n",
            "Running model 10/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 4,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92359\tvalid-mlogloss:1.92390\n",
            "[50]\ttrain-mlogloss:1.24854\tvalid-mlogloss:1.26281\n",
            "[100]\ttrain-mlogloss:0.90780\tvalid-mlogloss:0.92865\n",
            "[150]\ttrain-mlogloss:0.70342\tvalid-mlogloss:0.72835\n",
            "[200]\ttrain-mlogloss:0.57340\tvalid-mlogloss:0.60164\n",
            "[250]\ttrain-mlogloss:0.48515\tvalid-mlogloss:0.51630\n",
            "[300]\ttrain-mlogloss:0.42240\tvalid-mlogloss:0.45611\n",
            "[350]\ttrain-mlogloss:0.37786\tvalid-mlogloss:0.41398\n",
            "[400]\ttrain-mlogloss:0.34559\tvalid-mlogloss:0.38421\n",
            "[450]\ttrain-mlogloss:0.32048\tvalid-mlogloss:0.36186\n",
            "[500]\ttrain-mlogloss:0.29990\tvalid-mlogloss:0.34400\n",
            "[550]\ttrain-mlogloss:0.28364\tvalid-mlogloss:0.33059\n",
            "[600]\ttrain-mlogloss:0.27014\tvalid-mlogloss:0.31987\n",
            "[650]\ttrain-mlogloss:0.25874\tvalid-mlogloss:0.31142\n",
            "[700]\ttrain-mlogloss:0.24899\tvalid-mlogloss:0.30466\n",
            "[750]\ttrain-mlogloss:0.24050\tvalid-mlogloss:0.29881\n",
            "[800]\ttrain-mlogloss:0.23320\tvalid-mlogloss:0.29422\n",
            "[850]\ttrain-mlogloss:0.22666\tvalid-mlogloss:0.29009\n",
            "[900]\ttrain-mlogloss:0.22075\tvalid-mlogloss:0.28667\n",
            "[950]\ttrain-mlogloss:0.21538\tvalid-mlogloss:0.28371\n",
            "[1000]\ttrain-mlogloss:0.21029\tvalid-mlogloss:0.28132\n",
            "[1050]\ttrain-mlogloss:0.20572\tvalid-mlogloss:0.27944\n",
            "[1100]\ttrain-mlogloss:0.20134\tvalid-mlogloss:0.27764\n",
            "[1150]\ttrain-mlogloss:0.19723\tvalid-mlogloss:0.27610\n",
            "[1200]\ttrain-mlogloss:0.19320\tvalid-mlogloss:0.27472\n",
            "[1250]\ttrain-mlogloss:0.18943\tvalid-mlogloss:0.27368\n",
            "[1300]\ttrain-mlogloss:0.18567\tvalid-mlogloss:0.27259\n",
            "[1350]\ttrain-mlogloss:0.18202\tvalid-mlogloss:0.27178\n",
            "[1400]\ttrain-mlogloss:0.17847\tvalid-mlogloss:0.27104\n",
            "[1450]\ttrain-mlogloss:0.17528\tvalid-mlogloss:0.27049\n",
            "[1500]\ttrain-mlogloss:0.17228\tvalid-mlogloss:0.26982\n",
            "[1550]\ttrain-mlogloss:0.16931\tvalid-mlogloss:0.26920\n",
            "[1600]\ttrain-mlogloss:0.16648\tvalid-mlogloss:0.26891\n",
            "[1650]\ttrain-mlogloss:0.16380\tvalid-mlogloss:0.26856\n",
            "[1700]\ttrain-mlogloss:0.16115\tvalid-mlogloss:0.26819\n",
            "[1750]\ttrain-mlogloss:0.15856\tvalid-mlogloss:0.26794\n",
            "[1800]\ttrain-mlogloss:0.15597\tvalid-mlogloss:0.26778\n",
            "[1850]\ttrain-mlogloss:0.15355\tvalid-mlogloss:0.26768\n",
            "[1900]\ttrain-mlogloss:0.15101\tvalid-mlogloss:0.26759\n",
            "[1950]\ttrain-mlogloss:0.14875\tvalid-mlogloss:0.26749\n",
            "[2000]\ttrain-mlogloss:0.14649\tvalid-mlogloss:0.26750\n",
            "[2050]\ttrain-mlogloss:0.14428\tvalid-mlogloss:0.26746\n",
            "[2100]\ttrain-mlogloss:0.14201\tvalid-mlogloss:0.26749\n",
            "[2148]\ttrain-mlogloss:0.13998\tvalid-mlogloss:0.26765\n",
            "Model 10 training done in 32.0s, best_iteration=2048\n",
            "Validation accuracy (model 10): 0.90473\n",
            "Retraining model 10 on full data for 2049 rounds...\n",
            "Saved submission: submission_model_10.csv\n",
            "\n",
            "============================================================\n",
            "Running model 11/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.7,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92366\tvalid-mlogloss:1.92394\n",
            "[50]\ttrain-mlogloss:1.24852\tvalid-mlogloss:1.26279\n",
            "[100]\ttrain-mlogloss:0.90853\tvalid-mlogloss:0.92902\n",
            "[150]\ttrain-mlogloss:0.70372\tvalid-mlogloss:0.72846\n",
            "[200]\ttrain-mlogloss:0.57327\tvalid-mlogloss:0.60166\n",
            "[250]\ttrain-mlogloss:0.48486\tvalid-mlogloss:0.51612\n",
            "[300]\ttrain-mlogloss:0.42212\tvalid-mlogloss:0.45586\n",
            "[350]\ttrain-mlogloss:0.37715\tvalid-mlogloss:0.41354\n",
            "[400]\ttrain-mlogloss:0.34445\tvalid-mlogloss:0.38362\n",
            "[450]\ttrain-mlogloss:0.31911\tvalid-mlogloss:0.36108\n",
            "[500]\ttrain-mlogloss:0.29829\tvalid-mlogloss:0.34318\n",
            "[550]\ttrain-mlogloss:0.28204\tvalid-mlogloss:0.32979\n",
            "[600]\ttrain-mlogloss:0.26844\tvalid-mlogloss:0.31899\n",
            "[650]\ttrain-mlogloss:0.25726\tvalid-mlogloss:0.31074\n",
            "[700]\ttrain-mlogloss:0.24737\tvalid-mlogloss:0.30387\n",
            "[750]\ttrain-mlogloss:0.23877\tvalid-mlogloss:0.29817\n",
            "[800]\ttrain-mlogloss:0.23148\tvalid-mlogloss:0.29367\n",
            "[850]\ttrain-mlogloss:0.22476\tvalid-mlogloss:0.28965\n",
            "[900]\ttrain-mlogloss:0.21856\tvalid-mlogloss:0.28619\n",
            "[950]\ttrain-mlogloss:0.21294\tvalid-mlogloss:0.28352\n",
            "[1000]\ttrain-mlogloss:0.20779\tvalid-mlogloss:0.28116\n",
            "[1050]\ttrain-mlogloss:0.20288\tvalid-mlogloss:0.27912\n",
            "[1100]\ttrain-mlogloss:0.19833\tvalid-mlogloss:0.27735\n",
            "[1150]\ttrain-mlogloss:0.19403\tvalid-mlogloss:0.27579\n",
            "[1200]\ttrain-mlogloss:0.18980\tvalid-mlogloss:0.27431\n",
            "[1250]\ttrain-mlogloss:0.18608\tvalid-mlogloss:0.27329\n",
            "[1300]\ttrain-mlogloss:0.18231\tvalid-mlogloss:0.27227\n",
            "[1350]\ttrain-mlogloss:0.17874\tvalid-mlogloss:0.27153\n",
            "[1400]\ttrain-mlogloss:0.17532\tvalid-mlogloss:0.27085\n",
            "[1450]\ttrain-mlogloss:0.17214\tvalid-mlogloss:0.27026\n",
            "[1500]\ttrain-mlogloss:0.16902\tvalid-mlogloss:0.26953\n",
            "[1550]\ttrain-mlogloss:0.16597\tvalid-mlogloss:0.26906\n",
            "[1600]\ttrain-mlogloss:0.16318\tvalid-mlogloss:0.26876\n",
            "[1650]\ttrain-mlogloss:0.16036\tvalid-mlogloss:0.26855\n",
            "[1700]\ttrain-mlogloss:0.15765\tvalid-mlogloss:0.26841\n",
            "[1750]\ttrain-mlogloss:0.15497\tvalid-mlogloss:0.26810\n",
            "[1800]\ttrain-mlogloss:0.15234\tvalid-mlogloss:0.26793\n",
            "[1850]\ttrain-mlogloss:0.14989\tvalid-mlogloss:0.26764\n",
            "[1900]\ttrain-mlogloss:0.14731\tvalid-mlogloss:0.26752\n",
            "[1950]\ttrain-mlogloss:0.14486\tvalid-mlogloss:0.26751\n",
            "[2000]\ttrain-mlogloss:0.14249\tvalid-mlogloss:0.26759\n",
            "[2041]\ttrain-mlogloss:0.14067\tvalid-mlogloss:0.26773\n",
            "Model 11 training done in 31.1s, best_iteration=1941\n",
            "Validation accuracy (model 11): 0.90666\n",
            "Retraining model 11 on full data for 1942 rounds...\n",
            "Saved submission: submission_model_11.csv\n",
            "\n",
            "============================================================\n",
            "Running model 12/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.9,\n",
            "  \"colsample_bytree\": 0.8,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92340\tvalid-mlogloss:1.92364\n",
            "[50]\ttrain-mlogloss:1.23424\tvalid-mlogloss:1.24890\n",
            "[100]\ttrain-mlogloss:0.89328\tvalid-mlogloss:0.91488\n",
            "[150]\ttrain-mlogloss:0.68687\tvalid-mlogloss:0.71261\n",
            "[200]\ttrain-mlogloss:0.55966\tvalid-mlogloss:0.58908\n",
            "[250]\ttrain-mlogloss:0.47237\tvalid-mlogloss:0.50466\n",
            "[300]\ttrain-mlogloss:0.41131\tvalid-mlogloss:0.44643\n",
            "[350]\ttrain-mlogloss:0.36841\tvalid-mlogloss:0.40629\n",
            "[400]\ttrain-mlogloss:0.33644\tvalid-mlogloss:0.37709\n",
            "[450]\ttrain-mlogloss:0.31224\tvalid-mlogloss:0.35604\n",
            "[500]\ttrain-mlogloss:0.29235\tvalid-mlogloss:0.33953\n",
            "[550]\ttrain-mlogloss:0.27647\tvalid-mlogloss:0.32695\n",
            "[600]\ttrain-mlogloss:0.26358\tvalid-mlogloss:0.31741\n",
            "[650]\ttrain-mlogloss:0.25278\tvalid-mlogloss:0.30964\n",
            "[700]\ttrain-mlogloss:0.24356\tvalid-mlogloss:0.30340\n",
            "[750]\ttrain-mlogloss:0.23529\tvalid-mlogloss:0.29817\n",
            "[800]\ttrain-mlogloss:0.22797\tvalid-mlogloss:0.29394\n",
            "[850]\ttrain-mlogloss:0.22149\tvalid-mlogloss:0.29028\n",
            "[900]\ttrain-mlogloss:0.21554\tvalid-mlogloss:0.28708\n",
            "[950]\ttrain-mlogloss:0.21019\tvalid-mlogloss:0.28424\n",
            "[1000]\ttrain-mlogloss:0.20526\tvalid-mlogloss:0.28209\n",
            "[1050]\ttrain-mlogloss:0.20063\tvalid-mlogloss:0.28021\n",
            "[1100]\ttrain-mlogloss:0.19613\tvalid-mlogloss:0.27851\n",
            "[1150]\ttrain-mlogloss:0.19206\tvalid-mlogloss:0.27707\n",
            "[1200]\ttrain-mlogloss:0.18798\tvalid-mlogloss:0.27564\n",
            "[1250]\ttrain-mlogloss:0.18429\tvalid-mlogloss:0.27459\n",
            "[1300]\ttrain-mlogloss:0.18052\tvalid-mlogloss:0.27369\n",
            "[1350]\ttrain-mlogloss:0.17673\tvalid-mlogloss:0.27284\n",
            "[1400]\ttrain-mlogloss:0.17311\tvalid-mlogloss:0.27215\n",
            "[1450]\ttrain-mlogloss:0.16972\tvalid-mlogloss:0.27148\n",
            "[1500]\ttrain-mlogloss:0.16650\tvalid-mlogloss:0.27083\n",
            "[1550]\ttrain-mlogloss:0.16335\tvalid-mlogloss:0.27042\n",
            "[1600]\ttrain-mlogloss:0.16028\tvalid-mlogloss:0.27003\n",
            "[1650]\ttrain-mlogloss:0.15737\tvalid-mlogloss:0.26964\n",
            "[1700]\ttrain-mlogloss:0.15463\tvalid-mlogloss:0.26939\n",
            "[1750]\ttrain-mlogloss:0.15181\tvalid-mlogloss:0.26917\n",
            "[1800]\ttrain-mlogloss:0.14905\tvalid-mlogloss:0.26883\n",
            "[1850]\ttrain-mlogloss:0.14646\tvalid-mlogloss:0.26873\n",
            "[1900]\ttrain-mlogloss:0.14389\tvalid-mlogloss:0.26848\n",
            "[1950]\ttrain-mlogloss:0.14153\tvalid-mlogloss:0.26840\n",
            "[2000]\ttrain-mlogloss:0.13924\tvalid-mlogloss:0.26853\n",
            "[2042]\ttrain-mlogloss:0.13730\tvalid-mlogloss:0.26865\n",
            "Model 12 training done in 31.0s, best_iteration=1942\n",
            "Validation accuracy (model 12): 0.90602\n",
            "Retraining model 12 on full data for 1943 rounds...\n",
            "Saved submission: submission_model_12.csv\n",
            "\n",
            "============================================================\n",
            "Running model 13/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.007,\n",
            "  \"max_depth\": 6,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92855\tvalid-mlogloss:1.92888\n",
            "[50]\ttrain-mlogloss:1.37772\tvalid-mlogloss:1.39149\n",
            "[100]\ttrain-mlogloss:1.05839\tvalid-mlogloss:1.08061\n",
            "[150]\ttrain-mlogloss:0.84593\tvalid-mlogloss:0.87365\n",
            "[200]\ttrain-mlogloss:0.69781\tvalid-mlogloss:0.73001\n",
            "[250]\ttrain-mlogloss:0.58962\tvalid-mlogloss:0.62585\n",
            "[300]\ttrain-mlogloss:0.50859\tvalid-mlogloss:0.54827\n",
            "[350]\ttrain-mlogloss:0.44812\tvalid-mlogloss:0.49120\n",
            "[400]\ttrain-mlogloss:0.40190\tvalid-mlogloss:0.44826\n",
            "[450]\ttrain-mlogloss:0.36595\tvalid-mlogloss:0.41546\n",
            "[500]\ttrain-mlogloss:0.33659\tvalid-mlogloss:0.38911\n",
            "[550]\ttrain-mlogloss:0.31330\tvalid-mlogloss:0.36878\n",
            "[600]\ttrain-mlogloss:0.29402\tvalid-mlogloss:0.35235\n",
            "[650]\ttrain-mlogloss:0.27784\tvalid-mlogloss:0.33897\n",
            "[700]\ttrain-mlogloss:0.26402\tvalid-mlogloss:0.32812\n",
            "[750]\ttrain-mlogloss:0.25215\tvalid-mlogloss:0.31903\n",
            "[800]\ttrain-mlogloss:0.24208\tvalid-mlogloss:0.31167\n",
            "[850]\ttrain-mlogloss:0.23320\tvalid-mlogloss:0.30538\n",
            "[900]\ttrain-mlogloss:0.22537\tvalid-mlogloss:0.30035\n",
            "[950]\ttrain-mlogloss:0.21833\tvalid-mlogloss:0.29592\n",
            "[1000]\ttrain-mlogloss:0.21182\tvalid-mlogloss:0.29223\n",
            "[1050]\ttrain-mlogloss:0.20608\tvalid-mlogloss:0.28919\n",
            "[1100]\ttrain-mlogloss:0.20075\tvalid-mlogloss:0.28655\n",
            "[1150]\ttrain-mlogloss:0.19592\tvalid-mlogloss:0.28417\n",
            "[1200]\ttrain-mlogloss:0.19120\tvalid-mlogloss:0.28208\n",
            "[1250]\ttrain-mlogloss:0.18696\tvalid-mlogloss:0.28027\n",
            "[1300]\ttrain-mlogloss:0.18284\tvalid-mlogloss:0.27868\n",
            "[1350]\ttrain-mlogloss:0.17896\tvalid-mlogloss:0.27733\n",
            "[1400]\ttrain-mlogloss:0.17516\tvalid-mlogloss:0.27622\n",
            "[1450]\ttrain-mlogloss:0.17174\tvalid-mlogloss:0.27517\n",
            "[1500]\ttrain-mlogloss:0.16838\tvalid-mlogloss:0.27419\n",
            "[1550]\ttrain-mlogloss:0.16520\tvalid-mlogloss:0.27333\n",
            "[1600]\ttrain-mlogloss:0.16217\tvalid-mlogloss:0.27270\n",
            "[1650]\ttrain-mlogloss:0.15930\tvalid-mlogloss:0.27205\n",
            "[1700]\ttrain-mlogloss:0.15654\tvalid-mlogloss:0.27143\n",
            "[1750]\ttrain-mlogloss:0.15380\tvalid-mlogloss:0.27091\n",
            "[1800]\ttrain-mlogloss:0.15112\tvalid-mlogloss:0.27060\n",
            "[1850]\ttrain-mlogloss:0.14852\tvalid-mlogloss:0.27029\n",
            "[1900]\ttrain-mlogloss:0.14579\tvalid-mlogloss:0.26988\n",
            "[1950]\ttrain-mlogloss:0.14337\tvalid-mlogloss:0.26955\n",
            "[2000]\ttrain-mlogloss:0.14092\tvalid-mlogloss:0.26942\n",
            "[2050]\ttrain-mlogloss:0.13858\tvalid-mlogloss:0.26924\n",
            "[2100]\ttrain-mlogloss:0.13615\tvalid-mlogloss:0.26921\n",
            "[2150]\ttrain-mlogloss:0.13393\tvalid-mlogloss:0.26919\n",
            "[2200]\ttrain-mlogloss:0.13173\tvalid-mlogloss:0.26918\n",
            "[2250]\ttrain-mlogloss:0.12961\tvalid-mlogloss:0.26913\n",
            "[2300]\ttrain-mlogloss:0.12752\tvalid-mlogloss:0.26915\n",
            "[2350]\ttrain-mlogloss:0.12558\tvalid-mlogloss:0.26914\n",
            "[2400]\ttrain-mlogloss:0.12358\tvalid-mlogloss:0.26915\n",
            "[2428]\ttrain-mlogloss:0.12253\tvalid-mlogloss:0.26913\n",
            "Model 13 training done in 41.8s, best_iteration=2328\n",
            "Validation accuracy (model 13): 0.90441\n",
            "Retraining model 13 on full data for 2329 rounds...\n",
            "Saved submission: submission_model_13.csv\n",
            "\n",
            "============================================================\n",
            "Running model 14/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.02,\n",
            "  \"max_depth\": 4,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.90728\tvalid-mlogloss:1.90772\n",
            "[50]\ttrain-mlogloss:0.95736\tvalid-mlogloss:0.97259\n",
            "[100]\ttrain-mlogloss:0.63057\tvalid-mlogloss:0.65040\n",
            "[150]\ttrain-mlogloss:0.47812\tvalid-mlogloss:0.50133\n",
            "[200]\ttrain-mlogloss:0.39417\tvalid-mlogloss:0.42097\n",
            "[250]\ttrain-mlogloss:0.34312\tvalid-mlogloss:0.37323\n",
            "[300]\ttrain-mlogloss:0.30816\tvalid-mlogloss:0.34190\n",
            "[350]\ttrain-mlogloss:0.28515\tvalid-mlogloss:0.32319\n",
            "[400]\ttrain-mlogloss:0.26905\tvalid-mlogloss:0.31079\n",
            "[450]\ttrain-mlogloss:0.25575\tvalid-mlogloss:0.30146\n",
            "[500]\ttrain-mlogloss:0.24483\tvalid-mlogloss:0.29420\n",
            "[550]\ttrain-mlogloss:0.23557\tvalid-mlogloss:0.28876\n",
            "[600]\ttrain-mlogloss:0.22728\tvalid-mlogloss:0.28418\n",
            "[650]\ttrain-mlogloss:0.21984\tvalid-mlogloss:0.28069\n",
            "[700]\ttrain-mlogloss:0.21309\tvalid-mlogloss:0.27783\n",
            "[750]\ttrain-mlogloss:0.20682\tvalid-mlogloss:0.27528\n",
            "[800]\ttrain-mlogloss:0.20108\tvalid-mlogloss:0.27360\n",
            "[850]\ttrain-mlogloss:0.19553\tvalid-mlogloss:0.27198\n",
            "[900]\ttrain-mlogloss:0.19059\tvalid-mlogloss:0.27058\n",
            "[950]\ttrain-mlogloss:0.18583\tvalid-mlogloss:0.26948\n",
            "[1000]\ttrain-mlogloss:0.18159\tvalid-mlogloss:0.26839\n",
            "[1050]\ttrain-mlogloss:0.17729\tvalid-mlogloss:0.26788\n",
            "[1100]\ttrain-mlogloss:0.17338\tvalid-mlogloss:0.26745\n",
            "[1150]\ttrain-mlogloss:0.16961\tvalid-mlogloss:0.26663\n",
            "[1200]\ttrain-mlogloss:0.16592\tvalid-mlogloss:0.26647\n",
            "[1250]\ttrain-mlogloss:0.16243\tvalid-mlogloss:0.26642\n",
            "[1300]\ttrain-mlogloss:0.15899\tvalid-mlogloss:0.26615\n",
            "[1350]\ttrain-mlogloss:0.15567\tvalid-mlogloss:0.26611\n",
            "[1400]\ttrain-mlogloss:0.15241\tvalid-mlogloss:0.26632\n",
            "[1417]\ttrain-mlogloss:0.15143\tvalid-mlogloss:0.26630\n",
            "Model 14 training done in 19.8s, best_iteration=1318\n",
            "Validation accuracy (model 14): 0.90859\n",
            "Retraining model 14 on full data for 1319 rounds...\n",
            "Saved submission: submission_model_14.csv\n",
            "\n",
            "============================================================\n",
            "Running model 15/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0,\n",
            "  \"grow_policy\": \"lossguide\"\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92357\tvalid-mlogloss:1.92392\n",
            "[50]\ttrain-mlogloss:1.24781\tvalid-mlogloss:1.26244\n",
            "[100]\ttrain-mlogloss:0.90665\tvalid-mlogloss:0.92810\n",
            "[150]\ttrain-mlogloss:0.70210\tvalid-mlogloss:0.72772\n",
            "[200]\ttrain-mlogloss:0.57196\tvalid-mlogloss:0.60114\n",
            "[250]\ttrain-mlogloss:0.48357\tvalid-mlogloss:0.51588\n",
            "[300]\ttrain-mlogloss:0.42076\tvalid-mlogloss:0.45561\n",
            "[350]\ttrain-mlogloss:0.37610\tvalid-mlogloss:0.41348\n",
            "[400]\ttrain-mlogloss:0.34362\tvalid-mlogloss:0.38365\n",
            "[450]\ttrain-mlogloss:0.31830\tvalid-mlogloss:0.36125\n",
            "[500]\ttrain-mlogloss:0.29762\tvalid-mlogloss:0.34342\n",
            "[550]\ttrain-mlogloss:0.28127\tvalid-mlogloss:0.33003\n",
            "[600]\ttrain-mlogloss:0.26765\tvalid-mlogloss:0.31932\n",
            "[650]\ttrain-mlogloss:0.25620\tvalid-mlogloss:0.31099\n",
            "[700]\ttrain-mlogloss:0.24625\tvalid-mlogloss:0.30421\n",
            "[750]\ttrain-mlogloss:0.23768\tvalid-mlogloss:0.29846\n",
            "[800]\ttrain-mlogloss:0.23025\tvalid-mlogloss:0.29384\n",
            "[850]\ttrain-mlogloss:0.22353\tvalid-mlogloss:0.28968\n",
            "[900]\ttrain-mlogloss:0.21751\tvalid-mlogloss:0.28633\n",
            "[950]\ttrain-mlogloss:0.21202\tvalid-mlogloss:0.28333\n",
            "[1000]\ttrain-mlogloss:0.20682\tvalid-mlogloss:0.28091\n",
            "[1050]\ttrain-mlogloss:0.20220\tvalid-mlogloss:0.27904\n",
            "[1100]\ttrain-mlogloss:0.19775\tvalid-mlogloss:0.27737\n",
            "[1150]\ttrain-mlogloss:0.19359\tvalid-mlogloss:0.27582\n",
            "[1200]\ttrain-mlogloss:0.18950\tvalid-mlogloss:0.27452\n",
            "[1250]\ttrain-mlogloss:0.18571\tvalid-mlogloss:0.27355\n",
            "[1300]\ttrain-mlogloss:0.18194\tvalid-mlogloss:0.27253\n",
            "[1350]\ttrain-mlogloss:0.17820\tvalid-mlogloss:0.27168\n",
            "[1400]\ttrain-mlogloss:0.17452\tvalid-mlogloss:0.27099\n",
            "[1450]\ttrain-mlogloss:0.17127\tvalid-mlogloss:0.27030\n",
            "[1500]\ttrain-mlogloss:0.16812\tvalid-mlogloss:0.26966\n",
            "[1550]\ttrain-mlogloss:0.16510\tvalid-mlogloss:0.26914\n",
            "[1600]\ttrain-mlogloss:0.16212\tvalid-mlogloss:0.26877\n",
            "[1650]\ttrain-mlogloss:0.15935\tvalid-mlogloss:0.26848\n",
            "[1700]\ttrain-mlogloss:0.15662\tvalid-mlogloss:0.26810\n",
            "[1750]\ttrain-mlogloss:0.15392\tvalid-mlogloss:0.26781\n",
            "[1800]\ttrain-mlogloss:0.15126\tvalid-mlogloss:0.26766\n",
            "[1850]\ttrain-mlogloss:0.14873\tvalid-mlogloss:0.26751\n",
            "[1900]\ttrain-mlogloss:0.14608\tvalid-mlogloss:0.26735\n",
            "[1950]\ttrain-mlogloss:0.14377\tvalid-mlogloss:0.26726\n",
            "[2000]\ttrain-mlogloss:0.14140\tvalid-mlogloss:0.26731\n",
            "[2050]\ttrain-mlogloss:0.13913\tvalid-mlogloss:0.26726\n",
            "[2054]\ttrain-mlogloss:0.13897\tvalid-mlogloss:0.26727\n",
            "Model 15 training done in 34.1s, best_iteration=1955\n",
            "Validation accuracy (model 15): 0.90698\n",
            "Retraining model 15 on full data for 1956 rounds...\n",
            "Saved submission: submission_model_15.csv\n",
            "\n",
            "============================================================\n",
            "Running model 16/16 with params:\n",
            "{\n",
            "  \"objective\": \"multi:softprob\",\n",
            "  \"num_class\": 7,\n",
            "  \"eval_metric\": \"mlogloss\",\n",
            "  \"verbosity\": 0,\n",
            "  \"seed\": 42,\n",
            "  \"tree_method\": \"hist\",\n",
            "  \"eta\": 0.01,\n",
            "  \"max_depth\": 5,\n",
            "  \"subsample\": 0.8,\n",
            "  \"colsample_bytree\": 0.7,\n",
            "  \"min_child_weight\": 3,\n",
            "  \"alpha\": 0.01,\n",
            "  \"lambda\": 1.0,\n",
            "  \"grow_policy\": \"depthwise\"\n",
            "}\n",
            "============================================================\n",
            "[0]\ttrain-mlogloss:1.92357\tvalid-mlogloss:1.92392\n",
            "[50]\ttrain-mlogloss:1.24781\tvalid-mlogloss:1.26244\n",
            "[100]\ttrain-mlogloss:0.90665\tvalid-mlogloss:0.92810\n",
            "[150]\ttrain-mlogloss:0.70210\tvalid-mlogloss:0.72772\n",
            "[200]\ttrain-mlogloss:0.57196\tvalid-mlogloss:0.60114\n",
            "[250]\ttrain-mlogloss:0.48357\tvalid-mlogloss:0.51588\n",
            "[300]\ttrain-mlogloss:0.42076\tvalid-mlogloss:0.45561\n",
            "[350]\ttrain-mlogloss:0.37610\tvalid-mlogloss:0.41348\n",
            "[400]\ttrain-mlogloss:0.34362\tvalid-mlogloss:0.38365\n",
            "[450]\ttrain-mlogloss:0.31830\tvalid-mlogloss:0.36125\n",
            "[500]\ttrain-mlogloss:0.29762\tvalid-mlogloss:0.34342\n",
            "[550]\ttrain-mlogloss:0.28127\tvalid-mlogloss:0.33003\n",
            "[600]\ttrain-mlogloss:0.26765\tvalid-mlogloss:0.31932\n",
            "[650]\ttrain-mlogloss:0.25620\tvalid-mlogloss:0.31099\n",
            "[700]\ttrain-mlogloss:0.24625\tvalid-mlogloss:0.30421\n",
            "[750]\ttrain-mlogloss:0.23768\tvalid-mlogloss:0.29846\n",
            "[800]\ttrain-mlogloss:0.23025\tvalid-mlogloss:0.29384\n",
            "[850]\ttrain-mlogloss:0.22353\tvalid-mlogloss:0.28968\n",
            "[900]\ttrain-mlogloss:0.21751\tvalid-mlogloss:0.28633\n",
            "[950]\ttrain-mlogloss:0.21202\tvalid-mlogloss:0.28333\n",
            "[1000]\ttrain-mlogloss:0.20682\tvalid-mlogloss:0.28091\n",
            "[1050]\ttrain-mlogloss:0.20220\tvalid-mlogloss:0.27904\n",
            "[1100]\ttrain-mlogloss:0.19775\tvalid-mlogloss:0.27737\n",
            "[1150]\ttrain-mlogloss:0.19359\tvalid-mlogloss:0.27582\n",
            "[1200]\ttrain-mlogloss:0.18950\tvalid-mlogloss:0.27452\n",
            "[1250]\ttrain-mlogloss:0.18571\tvalid-mlogloss:0.27355\n",
            "[1300]\ttrain-mlogloss:0.18194\tvalid-mlogloss:0.27253\n",
            "[1350]\ttrain-mlogloss:0.17820\tvalid-mlogloss:0.27168\n",
            "[1400]\ttrain-mlogloss:0.17452\tvalid-mlogloss:0.27099\n",
            "[1450]\ttrain-mlogloss:0.17127\tvalid-mlogloss:0.27030\n",
            "[1500]\ttrain-mlogloss:0.16812\tvalid-mlogloss:0.26966\n",
            "[1550]\ttrain-mlogloss:0.16510\tvalid-mlogloss:0.26914\n",
            "[1600]\ttrain-mlogloss:0.16212\tvalid-mlogloss:0.26877\n",
            "[1650]\ttrain-mlogloss:0.15935\tvalid-mlogloss:0.26848\n",
            "[1700]\ttrain-mlogloss:0.15662\tvalid-mlogloss:0.26810\n",
            "[1750]\ttrain-mlogloss:0.15392\tvalid-mlogloss:0.26781\n",
            "[1800]\ttrain-mlogloss:0.15126\tvalid-mlogloss:0.26766\n",
            "[1850]\ttrain-mlogloss:0.14873\tvalid-mlogloss:0.26751\n",
            "[1900]\ttrain-mlogloss:0.14608\tvalid-mlogloss:0.26735\n",
            "[1950]\ttrain-mlogloss:0.14377\tvalid-mlogloss:0.26726\n",
            "[2000]\ttrain-mlogloss:0.14140\tvalid-mlogloss:0.26731\n",
            "[2050]\ttrain-mlogloss:0.13913\tvalid-mlogloss:0.26726\n",
            "[2055]\ttrain-mlogloss:0.13891\tvalid-mlogloss:0.26727\n",
            "Model 16 training done in 30.6s, best_iteration=1955\n",
            "Validation accuracy (model 16): 0.90698\n",
            "Retraining model 16 on full data for 1956 rounds...\n",
            "Saved submission: submission_model_16.csv\n",
            "\n",
            "Saved model results to model_results.csv\n",
            "Generated submission files: ['submission_model_1.csv', 'submission_model_2.csv', 'submission_model_3.csv', 'submission_model_4.csv', 'submission_model_5.csv', 'submission_model_6.csv', 'submission_model_7.csv', 'submission_model_8.csv', 'submission_model_9.csv', 'submission_model_10.csv', 'submission_model_11.csv', 'submission_model_12.csv', 'submission_model_13.csv', 'submission_model_14.csv', 'submission_model_15.csv', 'submission_model_16.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XwMX1P5jg0Hr"
      }
    }
  ]
}